{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifying ImageNet: the instant Caffe way\n",
    "===========================================\n",
    "\n",
    "Caffe has a Python interface, pycaffe, with a `caffe.Net` interface for models. There are both Python and MATLAB interfaces. While this example uses the off-the-shelf Python `caffe.Classifier` interface there is also a MATLAB example at `matlab/caffe/matcaffe_demo.m`.\n",
    "\n",
    "Before we begin, you must compile Caffe. You should add the Caffe module to your `PYTHONPATH` although this example includes it automatically. If you haven't yet done so, please refer to the [installation instructions](http://caffe.berkeleyvision.org/installation.html). This example uses our pre-trained CaffeNet model, an ILSVRC12 image classifier. You can download it by running `./scripts/download_model_binary.py models/bvlc_reference_caffenet` or let the first step of this example download it for you.\n",
    "\n",
    "Ready? Let's start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Make sure that caffe is on the python path:\n",
    "CAFFE_ROOT = '/home/waylonflinn/Development/caffe/'\n",
    "import sys\n",
    "sys.path.insert(0, CAFFE_ROOT + 'python')\n",
    "\n",
    "import caffe\n",
    "\n",
    "# Set the right path to your model definition file, pretrained model weights,\n",
    "# and the image you would like to classify.\n",
    "REF_MODEL_FILE = CAFFE_ROOT + 'models/bvlc_reference_caffenet/deploy.prototxt'\n",
    "REF_PRETRAINED = CAFFE_ROOT + 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'\n",
    "\n",
    "MODEL_FILE = './deploy.prototxt'\n",
    "PRETRAINED = './oxford102_iter_50000.caffemodel'\n",
    "\n",
    "RAW_DATA_DIR = './data/'\n",
    "FLOWER_FILE = RAW_DATA_DIR + 'imagelabels.mat'\n",
    "IMAGE_FILE = RAW_DATA_DIR + 'oxford102/jpg/image_00001.jpg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "flower_mat = loadmat(FLOWER_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flower_mat['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading a network is easy. `caffe.Classifier` takes care of everything. Note the arguments for configuring input preprocessing: mean subtraction switched on by giving a mean array, input channel swapping takes care of mapping RGB into the reference ImageNet model's BGR order, and raw scaling multiplies the feature scale from the input [0,1] to the ImageNet model's [0,255].\n",
    "\n",
    "We will set the phase to test since we are doing testing, and will first use CPU for the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imagenet_mean = np.load(CAFFE_ROOT + 'python/caffe/imagenet/ilsvrc_2012_mean.npy').mean(1).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caffe.set_mode_cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = caffe.Classifier(REF_MODEL_FILE, PRETRAINED,\n",
    "                       mean=imagenet_mean,\n",
    "                       channel_swap=(2,1,0),\n",
    "                       raw_scale=255,\n",
    "                       image_dims=(256, 256))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our example image with Caffe's image loading helper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from caffe.io import load_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_image = load_image(IMAGE_FILE)\n",
    "plt.imshow(input_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to classify. The default is to actually do 10 predictions, cropping the center and corners of the image as well as their mirrored versions, and average over the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = net.predict([input_image])  # predict takes any number of images, and formats them for the Caffe net automatically\n",
    "print('prediction shape: {0}'.format(prediction[0].shape))\n",
    "plt.plot(prediction[0])\n",
    "predicted_class_index = prediction[0].argmax()\n",
    "print('predicted class: {0} ({1})'.format(labels[predicted_class_index], predicted_class_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the prediction is 1000-dimensional, and is pretty sparse.\n",
    "\n",
    "The predicted class 281 is \"Tabby cat.\" Our pretrained model uses the synset ID ordering of the classes, as listed in `../data/ilsvrc12/synset_words.txt` if you fetch the auxiliary imagenet data by `../data/ilsvrc12/get_ilsvrc_aux.sh`. If you look at the top indices that maximize the prediction score, they are cats, foxes, and other cute mammals. Not unreasonable predictions, right?\n",
    "\n",
    "Now let's classify by the center crop alone by turning off oversampling. Note that this makes a single input, although if you inspect the model definition prototxt you'll see the network has a batch size of 10. The python wrapper handles batching and padding for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = net.predict([input_image], oversample=False)\n",
    "print('prediction shape: {0}'.format(prediction[0].shape))\n",
    "plt.plot(prediction[0])\n",
    "print('predicted class: {0}'.format(prediction[0].argmax()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Now, why don't we see how long it takes to perform the classification end to end? This result is run from an Intel i5 CPU, so you may observe some performance differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit net.predict([input_image])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may look a little slow, but note that time is spent on cropping, python interfacing, and running 10 images. For performance, if you really want to make prediction fast, you can optionally code in C++ and pipeline operations better. For experimenting and prototyping the current speed is fine.\n",
    "\n",
    "Let's time classifying a single image with input preprocessed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from caffe.io import oversample, resize_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Resize the image to the standard (256, 256) and oversample net input sized crops.\n",
    "input_oversampled = oversample([resize_image(input_image, net.image_dims)], net.crop_dims)\n",
    "# 'data' is the input blob name in the model definition, so we preprocess for that input.\n",
    "caffe_input = np.asarray([net.transformer.preprocess('data', in_) for in_ in input_oversampled])\n",
    "# forward() takes keyword args for the input blobs with preprocessed input arrays.\n",
    "%timeit net.forward(data=caffe_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so how about GPU? it is actually pretty easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "caffe.set_mode_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voila! Now we are in GPU mode. Let's see if the code gives the same result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = net.predict([input_image])\n",
    "print('prediction shape: {0}'.format(prediction[0].shape))\n",
    "plt.plot(prediction[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, everything is the same. And how about time consumption? The following benchmark is obtained on the same machine with a GTX 770 GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Full pipeline timing.\n",
    "%timeit net.predict([input_image])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Forward pass timing.\n",
    "%timeit net.forward(data=caffe_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty fast right? Not as fast as you expected? Indeed, in this python demo you are seeing only 4 times speedup. But remember - the GPU code is actually very fast, and the data loading, transformation and interfacing actually start to take **more** time than the actual conv. net computation itself!\n",
    "\n",
    "To fully utilize the power of GPUs, you really want to:\n",
    "\n",
    "* Use larger batches, and minimize python call and data transfer overheads.\n",
    "* Pipeline data load operations, like using a subprocess.\n",
    "* Code in C++. A little inconvenient, but maybe worth it if your dataset is really, really large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parting Words\n",
    "-------------\n",
    "\n",
    "So this is python! We hope the interface is easy enough for one to use. The python wrapper is interfaced with boost::python, and source code can be found at `python/caffe` with the main interface in `pycaffe.py` and the classification wrapper in `classifier.py`. If you have customizations to make, start there! Do let us know if you make improvements by sending a pull request!"
   ]
  }
 ],
 "metadata": {
  "description": "Use the pre-trained ImageNet model to classify images with the Python interface.",
  "example_name": "ImageNet classification",
  "include_in_docs": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  },
  "priority": 1
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
